{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095aa937-7426-4edc-8880-13df5f73cf69",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388fe82-c2b6-4b8b-b292-18a0b118fb2e",
   "metadata": {},
   "source": [
    "### Below code is too heavy to run on mac(need higher end system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae918cd0-b048-440d-a5fa-99c8df56a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import feature extraction functions from the available modules.\n",
    "# Ensure these modules are in your PYTHONPATH or in the same directory.\n",
    "from modules.shape_features import extract_nodule_features\n",
    "from modules.texture_features import extract_texture_features\n",
    "from modules.artifact_noise_features import extract_artifact_noise_features, get_bounding_box\n",
    "from modules.statistic_features import extract_intensity_features\n",
    "\n",
    "# Base directory for processed data\n",
    "data_processed_root = \"../data_processed\"\n",
    "\n",
    "# Define the two classes\n",
    "classes = [\"RealCancerous\", \"FakeAddedCancer\"]\n",
    "\n",
    "# List to store features for each nodule\n",
    "all_features = []\n",
    "\n",
    "# Iterate through each class folder\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(data_processed_root, cls)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        print(f\"Directory for class {cls} not found: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    # Iterate over each patient folder in this class\n",
    "    patient_dirs = [os.path.join(class_dir, d) for d in os.listdir(class_dir)\n",
    "                    if os.path.isdir(os.path.join(class_dir, d))]\n",
    "    for patient_dir in patient_dirs:\n",
    "        patient_id = os.path.basename(patient_dir)\n",
    "        # Full CT scan file is expected to be named as \"[patient_id]_full_volume.npy\"\n",
    "        ct_scan_path = os.path.join(patient_dir, f\"{patient_id}_full_volume.npy\")\n",
    "        if not os.path.isfile(ct_scan_path):\n",
    "            print(f\"CT volume not found for patient {patient_id} at {ct_scan_path}\")\n",
    "            continue\n",
    "        ct_volume = np.load(ct_scan_path)\n",
    "        \n",
    "        # Look for ASRG masks first; if none, then for CMW masks.\n",
    "        mask_files = [f for f in os.listdir(patient_dir) if f.endswith(\"_asrg_mask.npy\")]\n",
    "        if len(mask_files) == 0:\n",
    "            mask_files = [f for f in os.listdir(patient_dir) if f.endswith(\"_cmw_mask.npy\")]\n",
    "        \n",
    "        # If no mask files are found, skip this patient.\n",
    "        if len(mask_files) == 0:\n",
    "            print(f\"Warning: No nodule masks found for patient {patient_id}. Skipping patient.\")\n",
    "            continue\n",
    "        \n",
    "        # Process each mask file for this patient.\n",
    "        for mask_file in mask_files:\n",
    "            # Extract nodule number from the file name (assumes format: \"noduleNumber_asrg_mask.npy\" or \"noduleNumber_cmw_mask.npy\")\n",
    "            nodule_number = mask_file.split(\"_\")[0]\n",
    "            mask_path = os.path.join(patient_dir, mask_file)\n",
    "            mask = np.load(mask_path)\n",
    "            \n",
    "            # Obtain the ROI from the CT scan using the bounding box of the mask.\n",
    "            bbox = get_bounding_box(mask)\n",
    "            if bbox is None:\n",
    "                print(f\"Warning: No nodule found in mask {mask_file} for patient {patient_id}. Skipping this mask.\")\n",
    "                continue\n",
    "            roi = ct_volume[bbox]\n",
    "            \n",
    "            # Extract features using the available modules.\n",
    "            # Note: The artifact and noise features are now extracted using the updated module (edge sharpness removed).\n",
    "            shape_feats = extract_nodule_features(mask, spacing=(1, 1, 1))\n",
    "            texture_feats = extract_texture_features(roi)  # Uses default parameters for GLCM, GLRLM, and wavelet features.\n",
    "            artifact_noise_feats = extract_artifact_noise_features(ct_volume, mask)\n",
    "            intensity_feats = extract_intensity_features(roi)\n",
    "            \n",
    "            # Combine features into one dictionary.\n",
    "            features = {}\n",
    "            features.update(shape_feats)\n",
    "            features.update(texture_feats)\n",
    "            features.update(artifact_noise_feats)\n",
    "            features.update(intensity_feats)\n",
    "            \n",
    "            # Add identification information.\n",
    "            features[\"nodule_number\"] = nodule_number\n",
    "            features[\"patient_id\"] = patient_id\n",
    "            features[\"class\"] = cls\n",
    "            \n",
    "            all_features.append(features)\n",
    "\n",
    "# Create a DataFrame from the collected features.\n",
    "df_features = pd.DataFrame(all_features)\n",
    "\n",
    "# Save the DataFrame as a CSV file in the processed data root.\n",
    "output_csv_path = os.path.join(data_processed_root, \"nodule_features.csv\")\n",
    "df_features.to_csv(output_csv_path, index=False)\n",
    "print(f\"Feature extraction complete. CSV saved at: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32c5ca-fcb4-4e97-8145-3034de1f171c",
   "metadata": {},
   "source": [
    "## Broke down Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41d369d-f7eb-4261-897b-4b49bfb18aab",
   "metadata": {},
   "source": [
    "# Shape Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38270915-93d1-4276-979b-b5268159e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape-based feature extraction complete. CSV saved at: ../data_processed/nodule_features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import the shape-based feature extraction function.\n",
    "from modules.shape_features import extract_nodule_features\n",
    "\n",
    "# Base directory for processed data.\n",
    "data_processed_root = \"../data_processed\"\n",
    "\n",
    "# Define the two classes.\n",
    "classes = [\"RealCancerous\", \"FakeAddedCancer\"]\n",
    "\n",
    "# List to store shape-based features for each nodule.\n",
    "all_features = []\n",
    "\n",
    "# Iterate through each class folder.\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(data_processed_root, cls)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        print(f\"Directory for class {cls} not found: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    # Iterate over each patient folder within the class.\n",
    "    patient_dirs = [os.path.join(class_dir, d) for d in os.listdir(class_dir)\n",
    "                    if os.path.isdir(os.path.join(class_dir, d))]\n",
    "    for patient_dir in patient_dirs:\n",
    "        patient_id = os.path.basename(patient_dir)\n",
    "        # Full CT scan file: \"[patient_id]_full_volume.npy\"\n",
    "        ct_scan_path = os.path.join(patient_dir, f\"{patient_id}_full_volume.npy\")\n",
    "        if not os.path.isfile(ct_scan_path):\n",
    "            print(f\"CT volume not found for patient {patient_id} at {ct_scan_path}. Skipping patient.\")\n",
    "            continue\n",
    "        \n",
    "        # Look for ASRG masks first; if none, try CMW masks.\n",
    "        mask_files = [f for f in os.listdir(patient_dir) if f.endswith(\"_asrg_mask.npy\")]\n",
    "        if len(mask_files) == 0:\n",
    "            mask_files = [f for f in os.listdir(patient_dir) if f.endswith(\"_cmw_mask.npy\")]\n",
    "        \n",
    "        # If no mask files are found, skip this patient.\n",
    "        if len(mask_files) == 0:\n",
    "            print(f\"Warning: No nodule masks found for patient {patient_id}. Skipping patient.\")\n",
    "            continue\n",
    "        \n",
    "        # Process each nodule mask.\n",
    "        for mask_file in mask_files:\n",
    "            # Expecting mask file names like \"1_asrg_mask.npy\" or \"1_cmw_mask.npy\"\n",
    "            nodule_number = mask_file.split(\"_\")[0]\n",
    "            mask_path = os.path.join(patient_dir, mask_file)\n",
    "            try:\n",
    "                mask = np.load(mask_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading mask {mask_file} for patient {patient_id}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Extract shape-based features using the mask.\n",
    "            # Adjust the spacing tuple if needed (default assumes isotropic voxels of size 1).\n",
    "            shape_feats = extract_nodule_features(mask, spacing=(1, 1, 1))\n",
    "            \n",
    "            # Build the feature dictionary.\n",
    "            feature_dict = {\n",
    "                \"nodule_number\": nodule_number,\n",
    "                \"patient_id\": patient_id,\n",
    "                \"class\": cls\n",
    "            }\n",
    "            feature_dict.update(shape_feats)\n",
    "            all_features.append(feature_dict)\n",
    "\n",
    "# Create a DataFrame from the collected shape features.\n",
    "df_shape = pd.DataFrame(all_features)\n",
    "\n",
    "# Save the shape-based features to a CSV file.\n",
    "output_csv_path = os.path.join(data_processed_root, \"nodule_features.csv\")\n",
    "df_shape.to_csv(output_csv_path, index=False)\n",
    "print(f\"Shape-based feature extraction complete. CSV saved at: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49239889-6ec2-4842-b898-8fa226e8b90d",
   "metadata": {},
   "source": [
    "## Texture-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc146009-2a96-48f3-b49e-3e0c6ca395ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aashin10/LungCancerFraudDetector/Lvenv/lib/python3.11/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 1 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texture-based feature extraction complete. Updated CSV saved at: ../data_processed/nodule_features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import the texture-based feature extraction function and the bounding box helper.\n",
    "from modules.texture_features import extract_texture_features\n",
    "from modules.artifact_noise_features import get_bounding_box\n",
    "\n",
    "# Base directory for processed data.\n",
    "data_processed_root = \"../data_processed\"\n",
    "\n",
    "# Path to the existing features CSV (from the shape-based step).\n",
    "csv_path = os.path.join(data_processed_root, \"nodule_features.csv\")\n",
    "\n",
    "# Load the existing features DataFrame.\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# List to store texture feature dictionaries.\n",
    "texture_feature_list = []\n",
    "\n",
    "# Iterate over each row in the CSV.\n",
    "for index, row in df.iterrows():\n",
    "    # Convert patient_id and nodule_number to string to avoid type issues.\n",
    "    patient_id = str(row['patient_id'])\n",
    "    nodule_number = str(row['nodule_number'])\n",
    "    cls = str(row['class'])\n",
    "    \n",
    "    patient_dir = os.path.join(data_processed_root, cls, patient_id)\n",
    "    ct_scan_path = os.path.join(patient_dir, f\"{patient_id}_full_volume.npy\")\n",
    "    \n",
    "    if not os.path.isfile(ct_scan_path):\n",
    "        print(f\"CT scan not found for patient {patient_id}. Skipping row.\")\n",
    "        texture_feature_list.append({})\n",
    "        continue\n",
    "    ct_volume = np.load(ct_scan_path)\n",
    "    \n",
    "    # Look for the nodule mask: first try ASRG, then fall back to CMW.\n",
    "    mask_filename = f\"{nodule_number}_asrg_mask.npy\"\n",
    "    mask_path = os.path.join(patient_dir, mask_filename)\n",
    "    if not os.path.isfile(mask_path):\n",
    "        mask_filename = f\"{nodule_number}_cmw_mask.npy\"\n",
    "        mask_path = os.path.join(patient_dir, mask_filename)\n",
    "        if not os.path.isfile(mask_path):\n",
    "            print(f\"Mask not found for patient {patient_id}, nodule {nodule_number}. Skipping row.\")\n",
    "            texture_feature_list.append({})\n",
    "            continue\n",
    "    mask = np.load(mask_path)\n",
    "    \n",
    "    # Use the bounding box of the mask to extract the ROI from the CT scan.\n",
    "    bbox = get_bounding_box(mask)\n",
    "    if bbox is None:\n",
    "        print(f\"No nodule found in mask for patient {patient_id}, nodule {nodule_number}. Skipping row.\")\n",
    "        texture_feature_list.append({})\n",
    "        continue\n",
    "    roi = ct_volume[bbox]\n",
    "    \n",
    "    # Extract texture-based features from the ROI.\n",
    "    texture_feats = extract_texture_features(roi)\n",
    "    texture_feature_list.append(texture_feats)\n",
    "\n",
    "# Convert the texture feature dictionaries into a DataFrame.\n",
    "df_texture = pd.DataFrame(texture_feature_list)\n",
    "\n",
    "# Append the new texture columns to the original DataFrame.\n",
    "df_updated = pd.concat([df, df_texture], axis=1)\n",
    "\n",
    "# Save the updated DataFrame back to CSV.\n",
    "output_csv_path = os.path.join(data_processed_root, \"nodule_features.csv\")\n",
    "df_updated.to_csv(output_csv_path, index=False)\n",
    "print(f\"Texture-based feature extraction complete. Updated CSV saved at: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e170d53-6879-409b-934f-3edb6c3a01cc",
   "metadata": {},
   "source": [
    "## Artifact-Noise-Based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b0f71-a01d-4c07-a9b4-b2b628cd83a2",
   "metadata": {},
   "source": [
    "### Too Heavy to Run on Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db4c51-5859-4d9c-a20f-c87223a96ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import the artifact-noise feature extraction function.\n",
    "from modules.artifact_noise_features import extract_artifact_noise_features\n",
    "\n",
    "# Base directory for processed data.\n",
    "data_processed_root = \"../data_processed\"\n",
    "\n",
    "# Path to the existing CSV file (from previous steps).\n",
    "csv_path = os.path.join(data_processed_root, \"nodule_features.csv\")\n",
    "\n",
    "# Load the existing features DataFrame.\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# List to store artifact-noise feature dictionaries.\n",
    "artifact_feature_list = []\n",
    "\n",
    "# Iterate over each row (nodule) in the CSV.\n",
    "for index, row in df.iterrows():\n",
    "    # Convert values to string to ensure proper path construction.\n",
    "    patient_id = str(row['patient_id'])\n",
    "    nodule_number = str(row['nodule_number'])\n",
    "    cls = str(row['class'])\n",
    "    \n",
    "    patient_dir = os.path.join(data_processed_root, cls, patient_id)\n",
    "    ct_scan_path = os.path.join(patient_dir, f\"{patient_id}_full_volume.npy\")\n",
    "    \n",
    "    if not os.path.isfile(ct_scan_path):\n",
    "        print(f\"CT scan not found for patient {patient_id}. Skipping row.\")\n",
    "        artifact_feature_list.append({})\n",
    "        continue\n",
    "    ct_volume = np.load(ct_scan_path)\n",
    "    \n",
    "    # Look for the corresponding mask: first try ASRG mask, then fall back to CMW mask.\n",
    "    mask_filename = f\"{nodule_number}_asrg_mask.npy\"\n",
    "    mask_path = os.path.join(patient_dir, mask_filename)\n",
    "    if not os.path.isfile(mask_path):\n",
    "        mask_filename = f\"{nodule_number}_cmw_mask.npy\"\n",
    "        mask_path = os.path.join(patient_dir, mask_filename)\n",
    "        if not os.path.isfile(mask_path):\n",
    "            print(f\"Mask not found for patient {patient_id}, nodule {nodule_number}. Skipping row.\")\n",
    "            artifact_feature_list.append({})\n",
    "            continue\n",
    "    mask = np.load(mask_path)\n",
    "    \n",
    "    # Extract artifact-noise-based features using the full CT scan and the mask.\n",
    "    try:\n",
    "        artifact_feats = extract_artifact_noise_features(ct_volume, mask)\n",
    "        artifact_feature_list.append(artifact_feats)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing artifact-noise features for patient {patient_id}, nodule {nodule_number}: {e}\")\n",
    "        artifact_feature_list.append({})\n",
    "\n",
    "# Convert the artifact feature dictionaries to a DataFrame.\n",
    "df_artifact = pd.DataFrame(artifact_feature_list)\n",
    "\n",
    "# Append the new artifact-noise features to the original DataFrame.\n",
    "df_updated = pd.concat([df, df_artifact], axis=1)\n",
    "\n",
    "# Save the updated DataFrame back to CSV.\n",
    "output_csv_path = os.path.join(data_processed_root, \"nodule_features.csv\")\n",
    "df_updated.to_csv(output_csv_path, index=False)\n",
    "print(f\"Artifact-noise-based feature extraction complete. Updated CSV saved at: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c540c-6604-48ce-81e5-bce35eb6f189",
   "metadata": {},
   "source": [
    "## Statistics-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133909f4-be0a-4e28-8fa3-bcb28520dbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensity-based feature extraction complete. Updated CSV saved at: ../data_processed/nodule_features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import intensity-based feature extraction function.\n",
    "from modules.statistic_features import extract_intensity_features\n",
    "# Reuse the bounding box helper from the artifact_noise module.\n",
    "from modules.artifact_noise_features import get_bounding_box\n",
    "\n",
    "# Base directory for processed data.\n",
    "data_processed_root = \"../data_processed\"\n",
    "\n",
    "# Path to the existing features CSV file (from previous shape/texture steps).\n",
    "csv_path = os.path.join(data_processed_root, \"nodule_features.csv\")\n",
    "\n",
    "# Load the existing DataFrame.\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# List to store intensity feature dictionaries.\n",
    "intensity_feature_list = []\n",
    "\n",
    "# Iterate over each nodule entry.\n",
    "for index, row in df.iterrows():\n",
    "    # Ensure patient id and nodule number are strings.\n",
    "    patient_id = str(row['patient_id'])\n",
    "    nodule_number = str(row['nodule_number'])\n",
    "    cls = str(row['class'])\n",
    "    \n",
    "    # Build the patient directory and CT scan path.\n",
    "    patient_dir = os.path.join(data_processed_root, cls, patient_id)\n",
    "    ct_scan_path = os.path.join(patient_dir, f\"{patient_id}_full_volume.npy\")\n",
    "    \n",
    "    if not os.path.isfile(ct_scan_path):\n",
    "        print(f\"CT scan not found for patient {patient_id}. Skipping row.\")\n",
    "        intensity_feature_list.append({})\n",
    "        continue\n",
    "    ct_volume = np.load(ct_scan_path)\n",
    "    \n",
    "    # Locate the nodule mask (prefer ASRG, fall back to CMW).\n",
    "    mask_filename = f\"{nodule_number}_asrg_mask.npy\"\n",
    "    mask_path = os.path.join(patient_dir, mask_filename)\n",
    "    if not os.path.isfile(mask_path):\n",
    "        mask_filename = f\"{nodule_number}_cmw_mask.npy\"\n",
    "        mask_path = os.path.join(patient_dir, mask_filename)\n",
    "        if not os.path.isfile(mask_path):\n",
    "            print(f\"Mask not found for patient {patient_id}, nodule {nodule_number}. Skipping row.\")\n",
    "            intensity_feature_list.append({})\n",
    "            continue\n",
    "    mask = np.load(mask_path)\n",
    "    \n",
    "    # Extract the ROI from the CT scan using the bounding box of the mask.\n",
    "    bbox = get_bounding_box(mask)\n",
    "    if bbox is None:\n",
    "        print(f\"No nodule found in mask for patient {patient_id}, nodule {nodule_number}. Skipping row.\")\n",
    "        intensity_feature_list.append({})\n",
    "        continue\n",
    "    roi = ct_volume[bbox]\n",
    "    \n",
    "    # Extract intensity-based features (statistical moments, histogram analysis).\n",
    "    intensity_feats = extract_intensity_features(roi, num_bins=50)\n",
    "    intensity_feature_list.append(intensity_feats)\n",
    "\n",
    "# Convert the list of intensity feature dictionaries into a DataFrame.\n",
    "df_intensity = pd.DataFrame(intensity_feature_list)\n",
    "\n",
    "# Append the new intensity feature columns to the original DataFrame.\n",
    "df_updated = pd.concat([df, df_intensity], axis=1)\n",
    "\n",
    "# Save the updated DataFrame back to CSV.\n",
    "output_csv_path = os.path.join(data_processed_root, \"nodule_features.csv\")\n",
    "df_updated.to_csv(output_csv_path, index=False)\n",
    "print(f\"Intensity-based feature extraction complete. Updated CSV saved at: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b60333-4b24-4f8b-9f7f-cb948a0a1398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lvenv",
   "language": "python",
   "name": "lvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
